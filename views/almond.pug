extends layout

block styles
  link(rel='stylesheet', href='/stylesheets/index.css')

block scripts
  script(src='/javascripts/shared.js')
  script(src='/javascripts/index.js')

block page_name
  - stdlayout = false;
  | Almond

block content
  if authenticated
    div#cloud-id-holder(data-cloud-id=user.cloud_id, data-auth-token=user.auth_token)

  div#page-body
    section.divider#section-heading
      h1#almond-title Almond
      h2#almond-subtitle The Open Virtual Assistant

      if !authenticated
        div.container
          div.row
            div.col-xs-12.col-md-6.col-md-offset-3
              p=_("Almond lets you interact with your services and accounts in natural language, with flexibility and privacy.")

        p
          a(href='/get-almond').scroller.btn.btn-primary= _("Get Almond")
      else
        a(href='/me').btn.btn-primary= _("My Almond")
        | &nbsp;
        a(href='/me/conversation').btn.btn-primary= _("Web Almond")

    if IS_ALMOND_WEBSITE
      div.sections
        section.divider
          h3= _("Research Agenda")
          div.container
            div.row
              div.col-sm-6.col-lg-6
                div.project-icon#agenda-thingpedia
                div.project-details
                  h4 Thingpedia
                  p
                    | A non-proprietary repository of digital interfaces and their linguistic representation open to all
                    | virtual assistant platforms.  Unlike existing skill repositories, Thingpedia captures the full API
                    | signatures to support composition.  Plenty of research is still necessary to learn how to organize
                    | the information, standardize across devices with similar functions, and reduce quirkiness of specific
                    | interfaces to increase synthesizability from natural language.
                    | Besides launching campaigns to crowdsource the data, we plan to use data programming techniques
                    | to automate the acquisition of entries in Thingpedia.
                    | Thingpedia will be extended to include also compound commands consumers find useful as well as
                    | templates of personal data released under GDPR.
              div.col-sm-6.col-lg-6
                div.project-icon#agenda-thingtalk
                div.project-details
                  h4 ThingTalk
                  p
                    | A formal, synthesizable, virtual assistant programming language.  ThingTalk currently supports
                    | composition of skills, event monitoring, access control, and distributed execution.
                    | We plan to extend ThingTalk so (1) users can create custom tasks involving data-dependent decisions;
                    | (2) users can query their data easily, hiding the complexity of retrieving data from different cloud services;
                    | and (3) users can access and compute with data from their network of friends of friends.
            div.row
              div.col-sm-6.col-lg-6
                div.project-icon#agenda-luinet
                div.project-details
                  h4 LUInet
                  p
                    | Linguistic User Interface Neural Network, a neural network that understands natural language to code.
                    | We hope to collect real-life data through our own apps and our partners products.
                    | We also plan to refine the methodology to create new language discourses.
                    | Companies can use this to let workers customize an assistant for their workflow using corporate
                    | confidential APIs. Other research topics include automatically generating precise,
                    | yet natural, sentences to confirm the  commands, as well as the automatic generation of dialogs
                    | to help users discover the virtual assistant’s capabilities and to refine their commands.
              div.col-sm-6.col-lg-6
                div.project-icon#agenda-guinet
                div.project-details
                  h4 GUInet
                  p
                    | Graphical User Interface Neural Network, a neural network that translates natural language commands
                    | into graphical interfaces.  We plan to improve our existing models and apply the idea to many more
                    | applications.  We also plan to understand how we can combine LUI andGUI together to make the most
                    | out of both types of interfaces.
            div.row
              div.col-sm-6.col-lg-6
                div.project-icon#agenda-dtp
                div.project-details
                  h4 Distributed ThingTalk Protocol
                  p
                    | Distributed  ThingTalk  Protocol,  that  supports  sharing  with  privacy  via  cooperatingvirtual assistants.  We only have a rudimentary design to date;  we hope that this lab can bringthe  major  corporate  players  together  to  define,  evolve,  and  adopt  a  common  virtual  assistantcommunication protocol.

        section.divider
          h3= _("Projects in Progress")
          div.container
            div.row
              div.col-sm-6.col-lg-6
                div.project-icon#project-server
                div.project-details
                  h4 Platform-agnostic Skill Server
                  p
                    | Today, to reach Alexa and Google Assistant users, companies need to stand up a skill server to
                    | interface between the assistants and their own services.  We see an opportunity to create a
                    | platform-agnostic service that provides vendors with LUI technology that connects to different
                    | platforms.  Such a service lowers the programming complexity for the vendors, while making their
                    | skills readily available to other platforms, if desired.
              div.col-sm-6.col-lg-6
                div.project-icon#project-compound
                div.project-details
                  h4 Privacy-preserving Compound Command Service
                  p
                    | We plan to offer users an alternative to IFTTT, a web service that millions have used to automate
                    | their IoTs.  Unlike IFTTT, our service provides a natural-language interface and allows users to
                    | keep their credentials.
            div.row
              div.col-sm-6.col-lg-6
                div.project-icon#project-email
                div.project-details
                  h4 Natural-language Queries for Email Archives
                  p
                    | We plan to add a natural-language interface to ePADD, an email browsing tool developed by
                    | Stanford Library based on our research prototype Muse.
                    | It is used by 35 libraries including the New York Public Library, Museum of ModernArt,
                    | and libraries at Brown, Caltech, Harvard, MIT, UC Berkeley, UCLA.
                    | We plan to compare the effectiveness of LUIs with GUIs, with the help of actual users in these libraries.



        section.divider
          h3= _("Almond Timeline")
          section.timeline
            ul
              li
                div <time>October 2018</time>
                  br
                  a(href='/publications/ubicomp18')
                    cite Controlling Fine-Grain Sharing in Natural Language with a Virtual Assistant (UbiComp 2018)
                  br
                  | Giovanni Campagna, Silei Xu, Rakesh Ramesh, Michael Fischer, and Monica S. Lam
                  //br
                  //| In <i>Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT)</i>, 2018.
              li
                div <time>September 2018</time>
                  br
                  a(href='/publications/mobilehci18')
                    cite Brassau: Automatically Generating Graphical User Interfaces for Virtual Assistant (MobileHCI 2018)
                  br
                  | Michael Fischer, Giovanni Campagna, Silei Xu, and Monica S. Lam
                  //br
                  //| In <i>20th International Conference on Human-Computer Interaction with Mobile Devices and Services. (MobileHCI)</i>, 2018.
              li
                div <time>April 2017</time>
                  br
                  a(href='/publications/www17')
                    cite Almond: The Architecture of an Open, Crowdsourced, Privacy-Preserving, Programmable Virtual Assistant (WWW 2017)
                  br
                  | Giovanni Campagna, Rakesh Ramesh, Silei Xu, Michael Fischer, and Monica S. Lam
                  //br
                  //| In <i>Proceedings of the 26th International World Wide Web Conference (WWW-2017)</i>, Perth, Australia, April 2017.
              li
                div <time>May 2016</time>
                  br
                  a(href='/publications/mobilesoft16')
                    cite A Distributed Open Social Platform for Mobile Devices (MobileSoft 2016)
                  br
                  | Monica S. Lam, Giovanni Campagna, Jiwon Seo, and Michael Fischer
                  //br
                  //| In <i>IEEE/ACM International Conference on Mobile Software Engineering and Systems</i>, Austin, Texas, May 2016. (Keynote)
        section.divider
          h3= _("Open & Crowdsourced")
          div.container
            div.row
              div.col-md-6
                p
                  |  Almond draws its power from the crowdsourced <a href='/thingpedia'>Thingpedia</a>, an open collection of Web and Internet
                  |  of Things APIs.
                  |  Anyone can contribute support for the favorite service, with few lines of code and a handful of natural language sentences.

                p Thingpedia supports more than 40 different services, accounts and IoT devices.

                p
                  |  Almond is free software, and is available on <a href='https://github.com/Stanford-Mobisocial-IoT-Lab'>Github</a>. You can download, distribute or modify Almond as you see fit.
              div.col-md-6
                img(src='/images/thingpedia-icon-cloud.png',alt=_("The logos of the services supported by Almond"))#thingpedia-icon-cloud
        section.divider
          h3= _("Unprecedented Expressivity")
          div.container
            div.row
              div.col-md-6#multi-color-example
                p.box
                  span.black When the
                  span.blue  Bitcoin
                  span.red  price reaches $20,000
                  span.black ,
                  span.blue  search for
                  span.black  a
                  span.purple  “Bitcoin”
                  span.blue  picture
                  span.black , and
                  span.blue  tweet
                  span.green  it
                  span.black  with
                  span.purple  caption “I am rich!”
                p.arrow ⇓
                p.box
                  span.black
                    code monitor
                  span.blue  @bitcoin.get_price()
                  span.black
                    code  on
                  span.red  price &ge; $20000
                  span.black  ⇒
                  span.blue  @bing.image_search
                  span.black (
                  span.purple "bitcoin"
                  span.black ) ⇒
                  span.blue  @twitter.post
                  span.black (
                  span.green @bing.picture
                  span.black ,
                  span.purple  "I am rich!"
                  span.black )
              div.col-md-6
                p Almond is the world first virtual assistant to support <i>compound commands</i> in natural language.
                p
                  | In Almond, you can combine multiple services into a single command, with powerful filtering and passing of data from one to another.
                  | Do away with the complex UIs of IFTTT or Zapier - in Almond the power is ready for you to type.
                //p <a href='#section-try-now'>Try now</a>: “get Washington Post articles published in the last 2 hours”, ”translate tweets from @... to my language”
        section.divider
          h3= _("Respects Your Privacy (and That of Your Friends)")
          div.container
            div.row
              div.col-md-6
                p
                  | Almond is the world first <i>Communicating Virtual Assistant</i>: through Almond you can interact not only
                  |  with your services, but also access that of your friends, family and colleagues.

                p
                  | To protect your privacy, Almond allows you to set flexible access control policies, based on time of
                  | day, on your location, on the content of the request, or really on any information available to Almond.
                  | For example, your parents can monitor your security camera, <i>only if you're not home</i>, or <i>only
                  | at a certain time of the day</i>.

                p
                  | Finally, to guarantee your privacy, Almond runs all its actions and computation locally. If you so choose,
                  | you can have your own installation of Almond in your phone or your laptop. If you use Web Almond, your
                  | data is encrypted and stored in a secure enclave not accessible by anybody else.

              div.col-md-6
                img(src='/images/comma-security-camera-example.svg',alt=_("A dad can access the security camera of his daughter, until certain conditions specified by her."))
                img(src='/images/comma-arch.svg',alt=_("The architecture of communicating virtual assistants."))

        section.divider#publications
          h3= _("Publications & Talks")

          div.container
            div.row
              div.col-xs-12
                ul#publication-list
                  li
                    a(href='https://d1ge76rambtuys.cloudfront.net/papers/www17.pdf')
                      cite Almond: The Architecture of an Open, Crowdsourced, Privacy-Preserving, Programmable Virtual Assistant
                    br
                    | Giovanni Campagna, Rakesh Ramesh, Silei Xu, Michael Fischer, and Monica S. Lam
                    br
                    | In <i>Proceedings of the 26th International World Wide Web Conference (WWW-2017)</i>, Perth, Australia, April 2017.

                  li
                    a(href='http://mobisocial.stanford.edu/papers/mobilesoft16.pdf')
                      cite A Distributed Open Social Platform for Mobile Devices
                    br
                    | Monica S. Lam, Giovanni Campagna, Jiwon Seo, and Michael Fischer
                    br
                    | In <i>IEEE/ACM International Conference on Mobile Software Engineering and Systems</i>, Austin, Texas, May 2016. (Keynote)

        section.divider#team
          h3= _("Our Team")
          div.container
            div.row
              div.col-md-6
                div.row
                  div.col-sm-6
                    div
                      div.team-profile-mid#team-profile-mid-monica
                      div
                        h4.profile-name
                          a(href='https://suif.stanford.edu/~lam/') Prof. Monica Lam
                        p Monica Lam is a Professor in the Computer Science Department at Stanford University since 1988. She received a B.Sc. from University of British Columbia in 1980 and a Ph.D. in Computer S cience from Carnegie Mellon University in 1987. She is the Faculty Director of the Stanford MobiSocial Computing Laboratory and a co-PI in the POMI (Programmable Open Mobile Internet) 2020 project, which is an NSF Expedition started in 2008.

                  div.col-sm-6
                    div
                      div.team-profile-mid#team-profile-mid-rsocher
                      div
                        h4.profile-name
                          a(href='https://www.socher.org') Prof. Richard Socher
                        p Richard Socher is the chief scientist at Salesforce and an Adjunct Professor in the Computer Science Department at Stanford University. Previously, he was the founder and CEO/CTO of <a href='http://www.metamind.io/'>MetaMind</a>. He received his PhD in 2014 from Stanford University, and he currently teaches CS244N Natural Language Processing with Deep Learning.

              div.col-md-6
                div.col-sm-6
                  div.team-profile-mid#team-profile-mid-giovanni
                  div
                    h6.profile-name
                      a(href='https://web.stanford.edu/~gcampagn/') Giovanni Campagna
                    p Computer Science PhD student
                    p Platform backend, natural language, Thingpedia and ThingTalk design

                div.col-sm-6
                  div.team-profile-mid#team-profile-mid-michael
                  div
                    h6.profile-name Michael Fischer
                    p Computer Science PhD student
                    p UX design, HCI and graphics
                    br

                div.visible-sm.visible-md.visible-lg.clearfix

                div.col-sm-6
                  div.team-profile-mid#team-profile-mid-silei
                  div
                    h6.profile-name
                      a(href='https://cs.stanford.edu/people/silei/') Silei Xu
                    p Computer Science PhD student
                    p Systems, Thingpedia design, distributed system

                div.col-sm-6
                  div.team-profile-mid#team-profile-mid-rakesh
                  div
                    h6.profile-name
                      a(href='https://people.stanford.edu/rakeshr1/') Rakesh Ramesh
                    p Electrical Engineering PhD student
                    p Natural language understanding

                div.visible-sm.visible-md.visible-lg.clearfix

                div.col-sm-6
                  div.team-profile-mid#team-profile-mid-mehrad
                  div
                    h6.profile-name
                      a(href='https://www.linkedin.com/in/mehradmoradshahi/') Mehrad Moradshahi
                    p Electrical Engineering PhD student
                    p Natural language understanding
                    br

                div.col-sm-6
                  div.team-profile-mid#team-profile-mid-richard
                  div
                    h6.profile-name Richard Yang
                    p Computer Science MS student
                    p HCI and graphics

            div.row
              div.col-sm-12
                p.text-center
                  small Previous members of our team include Albert Chen, Zhiyang He, Jiaqi Xue,
                    |  Aashna Garg, Jiwon Seo, Sadjad Fouladi and Reynis Vazquez. We thank them for their valuable support.
